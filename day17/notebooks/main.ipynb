{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df083398",
   "metadata": {},
   "source": [
    "# Day 17: ARIMA Diagnostics\n",
    "## Residual Analysis for Model Validation\n",
    "\n",
    "This notebook validates ARIMA(0,1,0) model assumptions through comprehensive residual diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f1cf8e",
   "metadata": {},
   "source": [
    "## Section 1: Import and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eefedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.subplots as sp\n",
    "from scipy import stats\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc5b26",
   "metadata": {},
   "source": [
    "## Section 2: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4f084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../data/gold_prices.csv', parse_dates=['Date'])\n",
    "if 'Price' not in df.columns:\n",
    "    df = df.rename(columns={'Adj Close': 'Price'})\n",
    "df = df.drop_duplicates(subset=['Date']).sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df[:train_size].copy()\n",
    "test_data = df[train_size:].copy()\n",
    "\n",
    "print(f\"Data loaded: {len(df)} observations\")\n",
    "print(f\"Train: {len(train_data)} | Test: {len(test_data)}\")\n",
    "print(f\"Date range: {df['Date'].min().date()} to {df['Date'].max().date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360e99ef",
   "metadata": {},
   "source": [
    "## Section 3: Fit ARIMA(0,1,0) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc18c7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit optimal ARIMA(0,1,0) from Day 16\n",
    "model = ARIMA(train_data['Price'], order=(0, 1, 0))\n",
    "fitted_model = model.fit()\n",
    "\n",
    "print(f\"Model: ARIMA(0,1,0)\")\n",
    "print(f\"AIC: {fitted_model.aic:.2f}\")\n",
    "print(f\"BIC: {fitted_model.bic:.2f}\")\n",
    "print(f\"\\nModel Summary:\")\n",
    "print(fitted_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7af3b7",
   "metadata": {},
   "source": [
    "## Section 4: Extract and Analyze Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144384d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-sample residuals\n",
    "residuals = fitted_model.resid.dropna()\n",
    "\n",
    "print(\"In-Sample Residual Statistics:\")\n",
    "print(f\"  Count: {len(residuals)}\")\n",
    "print(f\"  Mean: {residuals.mean():.6f}\")\n",
    "print(f\"  Std Dev: {residuals.std():.6f}\")\n",
    "print(f\"  Min: {residuals.min():.2f}\")\n",
    "print(f\"  Max: {residuals.max():.2f}\")\n",
    "print(f\"  Median: {residuals.median():.2f}\")\n",
    "print(f\"  Skewness: {stats.skew(residuals):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(residuals):.4f}\")\n",
    "\n",
    "# Test set residuals\n",
    "forecast = fitted_model.get_forecast(steps=len(test_data))\n",
    "forecast_values = forecast.predicted_mean.values\n",
    "test_residuals = test_data['Price'].values - forecast_values\n",
    "\n",
    "print(f\"\\nTest Set Residual Statistics:\")\n",
    "print(f\"  Count: {len(test_residuals)}\")\n",
    "print(f\"  Mean: {test_residuals.mean():.2f}\")\n",
    "print(f\"  Std Dev: {test_residuals.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca55463",
   "metadata": {},
   "source": [
    "## Section 5: Ljung-Box Test (Autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f5aac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ljung-Box test at multiple lags\n",
    "lags_to_test = [5, 10, 20, 40]\n",
    "lb_results = acorr_ljungbox(residuals, lags=lags_to_test, return_df=True)\n",
    "\n",
    "print(\"Ljung-Box Test Results:\")\n",
    "print(\"H0: Residuals are white noise (no autocorrelation)\\n\")\n",
    "print(lb_results)\n",
    "\n",
    "alpha = 0.05\n",
    "print(f\"\\nInterpretation (α = {alpha}):\")\n",
    "for lag in lags_to_test:\n",
    "    p_val = lb_results.loc[lag, 'lb_pvalue']\n",
    "    is_white = p_val > alpha\n",
    "    status = \"✓ PASS\" if is_white else \"✗ FAIL\"\n",
    "    print(f\"  Lag {lag:2d}: p={p_val:.4f} → {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1e1a52",
   "metadata": {},
   "source": [
    "## Section 6: Jarque-Bera Test (Normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e340086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jarque-Bera test\n",
    "jb_stat, jb_pvalue = stats.jarque_bera(residuals)\n",
    "skewness = stats.skew(residuals)\n",
    "kurtosis = stats.kurtosis(residuals)\n",
    "\n",
    "print(\"Jarque-Bera Test for Normality:\")\n",
    "print(\"H0: Residuals follow normal distribution\\n\")\n",
    "print(f\"Test Statistic: {jb_stat:.4f}\")\n",
    "print(f\"P-value: {jb_pvalue:.4f}\")\n",
    "print(f\"Skewness: {skewness:.4f} (ideal: 0)\")\n",
    "print(f\"Kurtosis: {kurtosis:.4f} (ideal: 0)\")\n",
    "\n",
    "alpha = 0.05\n",
    "is_normal = jb_pvalue > alpha\n",
    "status = \"✓ PASS\" if is_normal else \"✗ FAIL\"\n",
    "print(f\"\\nInterpretation (α = {alpha}):\")\n",
    "print(f\"  Result: {status} - Residuals {'are' if is_normal else 'are NOT'} normally distributed\")\n",
    "\n",
    "if abs(skewness) < 0.5:\n",
    "    print(f\"  Skewness: ✓ Acceptable\")\n",
    "else:\n",
    "    print(f\"  Skewness: ✗ High asymmetry\")\n",
    "    \n",
    "if abs(kurtosis) < 1.0:\n",
    "    print(f\"  Kurtosis: ✓ Acceptable\")\n",
    "else:\n",
    "    print(f\"  Kurtosis: ✗ Heavy/light tails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58aedc83",
   "metadata": {},
   "source": [
    "## Section 7: Heteroskedasticity Test (Variance Stability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4035efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling variance analysis\n",
    "window = 50\n",
    "rolling_var = pd.Series(residuals).rolling(window=window).var()\n",
    "\n",
    "mean_var_first = rolling_var[:len(rolling_var)//2].mean()\n",
    "mean_var_second = rolling_var[len(rolling_var)//2:].mean()\n",
    "h_statistic = mean_var_second / mean_var_first if mean_var_first > 0 else 1.0\n",
    "\n",
    "print(\"Heteroskedasticity Test (Variance Stability):\")\n",
    "print(\"H0: Variance is constant over time\\n\")\n",
    "print(f\"Rolling Variance Analysis (window={window}):\")\n",
    "print(f\"  First half mean variance: {mean_var_first:.2f}\")\n",
    "print(f\"  Second half mean variance: {mean_var_second:.2f}\")\n",
    "print(f\"  H-statistic (ratio): {h_statistic:.4f}\")\n",
    "\n",
    "is_homoscedastic = 0.8 < h_statistic < 1.25\n",
    "status = \"✓ PASS\" if is_homoscedastic else \"✗ FAIL\"\n",
    "print(f\"\\nInterpretation:\")\n",
    "if is_homoscedastic:\n",
    "    print(f\"  {status} - Variances are relatively constant\")\n",
    "else:\n",
    "    print(f\"  {status} - Evidence of heteroscedasticity (volatility clustering)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673c6d41",
   "metadata": {},
   "source": [
    "## Section 8: ACF and PACF of Residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5cb5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ACF and PACF\n",
    "acf_values = acf(residuals, nlags=40, fft=True)\n",
    "pacf_values = pacf(residuals, nlags=40, method='ywm')\n",
    "\n",
    "# Count significant lags\n",
    "ci = 1.96 / np.sqrt(len(residuals))\n",
    "significant_acf = np.sum(np.abs(acf_values[1:]) > ci)\n",
    "significant_pacf = np.sum(np.abs(pacf_values[1:]) > ci)\n",
    "\n",
    "print(\"ACF and PACF Analysis:\")\n",
    "print(f\"Confidence interval: ±{ci:.4f}\\n\")\n",
    "print(f\"Autocorrelation Function (ACF):\")\n",
    "print(f\"  Significant lags (out of 40): {significant_acf}\")\n",
    "print(f\"  Expected by chance (α=0.05): ~2\")\n",
    "status_acf = \"✓ PASS\" if significant_acf <= 3 else \"✗ FAIL\"\n",
    "print(f\"  Status: {status_acf}\")\n",
    "\n",
    "print(f\"\\nPartial Autocorrelation Function (PACF):\")\n",
    "print(f\"  Significant lags (out of 40): {significant_pacf}\")\n",
    "print(f\"  Expected by chance (α=0.05): ~2\")\n",
    "status_pacf = \"✓ PASS\" if significant_pacf <= 3 else \"✗ FAIL\"\n",
    "print(f\"  Status: {status_pacf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbde004",
   "metadata": {},
   "source": [
    "## Section 9: Visualization - Diagnostic Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3cc149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive diagnostic visualization\n",
    "fig = sp.make_subplots(\n",
    "    rows=3, cols=2,\n",
    "    subplot_titles=(\n",
    "        'Residuals Over Time',\n",
    "        'Residual Distribution',\n",
    "        'Q-Q Plot',\n",
    "        'ACF of Residuals',\n",
    "        'PACF of Residuals',\n",
    "        'Rolling Mean and Variance'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{'type': 'scatter'}, {'type': 'histogram'}],\n",
    "        [{'type': 'scatter'}, {'type': 'bar'}],\n",
    "        [{'type': 'bar'}, {'type': 'scatter'}]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Residuals over time\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train_data['Date'],\n",
    "        y=residuals,\n",
    "        mode='markers',\n",
    "        marker=dict(color='#FF6B6B', size=4),\n",
    "        name='Residuals'\n",
    "    ),\n",
    "    row=1, col=1\n",
    ")\n",
    "fig.add_hline(y=0, line_dash='dash', line_color='black', row=1, col=1)\n",
    "\n",
    "# 2. Distribution\n",
    "fig.add_trace(\n",
    "    go.Histogram(\n",
    "        x=residuals,\n",
    "        nbinsx=40,\n",
    "        marker=dict(color='#FFD700'),\n",
    "        name='Distribution'\n",
    "    ),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# 3. Q-Q Plot\n",
    "sorted_residuals = np.sort(residuals)\n",
    "theoretical_quantiles = stats.norm.ppf(np.linspace(0.01, 0.99, len(sorted_residuals)))\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=theoretical_quantiles,\n",
    "        y=sorted_residuals,\n",
    "        mode='markers',\n",
    "        marker=dict(color='#4ECDC4', size=5),\n",
    "        name='Q-Q'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "min_val = min(theoretical_quantiles.min(), sorted_residuals.min())\n",
    "max_val = max(theoretical_quantiles.max(), sorted_residuals.max())\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=[min_val, max_val],\n",
    "        y=[min_val, max_val],\n",
    "        mode='lines',\n",
    "        line=dict(color='black', dash='dash'),\n",
    "        name='Normal'\n",
    "    ),\n",
    "    row=2, col=1\n",
    ")\n",
    "\n",
    "# 4. ACF\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=np.arange(len(acf_values)),\n",
    "        y=acf_values,\n",
    "        marker=dict(color='#95E1D3'),\n",
    "        name='ACF'\n",
    "    ),\n",
    "    row=2, col=2\n",
    ")\n",
    "ci = 1.96 / np.sqrt(len(residuals))\n",
    "fig.add_hline(y=ci, line_dash='dash', line_color='red', row=2, col=2)\n",
    "fig.add_hline(y=-ci, line_dash='dash', line_color='red', row=2, col=2)\n",
    "\n",
    "# 5. PACF\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=np.arange(len(pacf_values)),\n",
    "        y=pacf_values,\n",
    "        marker=dict(color='#A8D8EA'),\n",
    "        name='PACF'\n",
    "    ),\n",
    "    row=3, col=1\n",
    ")\n",
    "fig.add_hline(y=ci, line_dash='dash', line_color='red', row=3, col=1)\n",
    "fig.add_hline(y=-ci, line_dash='dash', line_color='red', row=3, col=1)\n",
    "\n",
    "# 6. Rolling statistics\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train_data['Date'],\n",
    "        y=pd.Series(residuals).rolling(window=50).mean(),\n",
    "        mode='lines',\n",
    "        name='Rolling Mean',\n",
    "        line=dict(color='blue')\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=train_data['Date'],\n",
    "        y=pd.Series(residuals).rolling(window=50).std(),\n",
    "        mode='lines',\n",
    "        name='Rolling Std',\n",
    "        line=dict(color='red')\n",
    "    ),\n",
    "    row=3, col=2\n",
    ")\n",
    "\n",
    "fig.update_yaxes(title_text=\"Residual\", row=1, col=1)\n",
    "fig.update_yaxes(title_text=\"Frequency\", row=1, col=2)\n",
    "fig.update_yaxes(title_text=\"Theoretical\", row=2, col=1)\n",
    "fig.update_yaxes(title_text=\"ACF\", row=2, col=2)\n",
    "fig.update_yaxes(title_text=\"PACF\", row=3, col=1)\n",
    "fig.update_yaxes(title_text=\"Value\", row=3, col=2)\n",
    "\n",
    "fig.update_layout(height=1200, width=1400, showlegend=True, hovermode='x unified')\n",
    "fig.show()\n",
    "\n",
    "print(\"✓ Diagnostic visualization created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6572d6",
   "metadata": {},
   "source": [
    "## Section 10: Summary and Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab34b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary table\n",
    "diagnostic_results = {\n",
    "    'Test': [\n",
    "        'Ljung-Box (lag 20)',\n",
    "        'Jarque-Bera',\n",
    "        'Heteroskedasticity',\n",
    "        'ACF Significant Lags',\n",
    "        'PACF Significant Lags'\n",
    "    ],\n",
    "    'Statistic': [\n",
    "        f\"{lb_results.loc[20, 'lb_stat']:.4f}\",\n",
    "        f\"{jb_stat:.4f}\",\n",
    "        f\"{h_statistic:.4f}\",\n",
    "        f\"{significant_acf}\",\n",
    "        f\"{significant_pacf}\"\n",
    "    ],\n",
    "    'P-Value': [\n",
    "        f\"{lb_results.loc[20, 'lb_pvalue']:.4f}\",\n",
    "        f\"{jb_pvalue:.4f}\",\n",
    "        \"N/A\",\n",
    "        \"N/A\",\n",
    "        \"N/A\"\n",
    "    ],\n",
    "    'Status': [\n",
    "        '✓ PASS' if lb_results.loc[20, 'lb_pvalue'] > 0.05 else '✗ FAIL',\n",
    "        '✓ PASS' if jb_pvalue > 0.05 else '✗ FAIL',\n",
    "        '✓ PASS' if 0.8 < h_statistic < 1.25 else '✗ FAIL',\n",
    "        '✓ PASS' if significant_acf <= 3 else '✗ FAIL',\n",
    "        '✓ PASS' if significant_pacf <= 3 else '✗ FAIL'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(diagnostic_results)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DIAGNOSTIC TEST RESULTS\")\n",
    "print(\"=\"*70)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Overall assessment\n",
    "all_passed = all([\n",
    "    lb_results.loc[20, 'lb_pvalue'] > 0.05,\n",
    "    jb_pvalue > 0.05,\n",
    "    0.8 < h_statistic < 1.25,\n",
    "    significant_acf <= 3,\n",
    "    significant_pacf <= 3\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OVERALL ASSESSMENT\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_passed:\n",
    "    print(\"✓ EXCELLENT - All diagnostic tests passed!\")\n",
    "    print(\"Model assumptions satisfied. Residuals are white noise.\")\n",
    "    print(\"Safe to use for forecasting and inference.\")\n",
    "else:\n",
    "    print(\"⚠ PARTIAL - Some diagnostic tests failed.\")\n",
    "    print(\"Review failing tests and consider model refinement.\")\n",
    "\n",
    "# Forecast performance\n",
    "rmse = np.sqrt(mean_squared_error(test_data['Price'], forecast_values))\n",
    "mae = mean_absolute_error(test_data['Price'], forecast_values)\n",
    "mape = np.mean(np.abs((test_data['Price'] - forecast_values) / test_data['Price'])) * 100\n",
    "\n",
    "print(f\"\\nForecast Performance:\")\n",
    "print(f\"  RMSE: {rmse:.2f}\")\n",
    "print(f\"  MAE: {mae:.2f}\")\n",
    "print(f\"  MAPE: {mape:.2f}%\")\n",
    "\n",
    "# Naive baseline\n",
    "naive_forecast = np.full(len(test_data), train_data['Price'].iloc[-1])\n",
    "naive_rmse = np.sqrt(mean_squared_error(test_data['Price'], naive_forecast))\n",
    "improvement = (naive_rmse - rmse) / naive_rmse * 100\n",
    "\n",
    "print(f\"\\nComparison to Naive Baseline:\")\n",
    "print(f\"  Naive RMSE: {naive_rmse:.2f}\")\n",
    "print(f\"  ARIMA RMSE: {rmse:.2f}\")\n",
    "print(f\"  Improvement: {improvement:+.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
